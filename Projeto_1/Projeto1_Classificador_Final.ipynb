{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: **Gianluca Lazzaris Giudici**\n",
    "\n",
    "Nome: **Pietro Abe Seixas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposta\n",
    "\n",
    "Neste projeto a partir de um analisador de Naive-Bayes, a proposta √© criar um identificador de sentimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import functools\n",
    "import operator\n",
    "from random import shuffle\n",
    "\n",
    "try:\n",
    "    import emoji\n",
    "except:\n",
    "    !pip install emoji --upgrade\n",
    "    import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "/Users/macbookpro/Documents/Git/cdados/Projeto_1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aqui no mcdonalds pra tentar matar a minha rai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@rafaamrtz @mcdonalds_br quer ir agoraaa??? ü§≠</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ialanau @zipzop26169213 @mcdonalds_br aonde e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mcdonalds_br postou errado n√© estagiario</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@igorneumann27 @mcdonalds_br um big tasty com ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0  aqui no mcdonalds pra tentar matar a minha rai...              0\n",
       "1      @rafaamrtz @mcdonalds_br quer ir agoraaa??? ü§≠              0\n",
       "2  @ialanau @zipzop26169213 @mcdonalds_br aonde e...              0\n",
       "3          @mcdonalds_br postou errado n√© estagiario              0\n",
       "4  @igorneumann27 @mcdonalds_br um big tasty com ...              0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treinamento = pd.read_excel('mcdonalds.xlsx')\n",
    "dados_teste = pd.read_excel(\"mcdonalds.xlsx\", \"Teste\")\n",
    "dados_treinamento.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "**O produto escolhido foi a empresa \"McDonalds\", onde separamos em dois grupos: relevantes, sendo esse identificado pelo numero 1 na coluna de classifica√ß√£o do excel, onde selecionamos tweets que possam ser ut√©is para a empresa escolhida melhorar seu atendimento em alguma de suas ar√©as; irrelevantes, sendo esse identificado pelo numero 0 na coluna de classifica√ß√£o do excel, onde foi selecionado tweets que n√£o ajudam em nada o McDonalds a melhor em algo no seu atendimento.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos dados.\n",
    "\n",
    "Podemos perceber, que os tweets que foram obtidos possuem pontua√ß√£o, emojis, e alguns caract√©res como **\\n**, que ir√£o poluir a an√°lise.\n",
    "\n",
    "Com isso, resolvemos utilizar algumas fun√ß√µes para fazer a limpeza dos dados, facilitando a an√°lise.\n",
    "\n",
    "Primeiro, separando os dados para facilitar a visualiza√ß√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento_relevantes = dados_treinamento.loc[dados_treinamento.Classifica√ß√£o == 1]\n",
    "dados_treinamento_nao_relevantes = dados_treinamento.loc[dados_treinamento.Classifica√ß√£o == 0]\n",
    "\n",
    "treinamento_string_relevantes = \"\"\n",
    "treinamento_string_nao_relevantes = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construindo fun√ß√µes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devido a grande quantidade de risadas \"kkk\" com diferentes tamanhos, iremos padronizar as risadas.\n",
    "def verifica_k(palavra):\n",
    "    for letra in palavra:\n",
    "        if letra != \"k\":\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def limpa_texto(texto):\n",
    "    \n",
    "    \n",
    "    texto_separa_emoji = emoji.get_emoji_regexp().split(texto)\n",
    "    texto_separa_espaco = [substr.split() for substr in texto_separa_emoji]\n",
    "    texto_separado = functools.reduce(operator.concat, texto_separa_espaco)\n",
    "    texto_separado = \" \".join(palavra for palavra in texto_separado)\n",
    "    \n",
    "    texto = \" \".join(palavra for palavra in texto_separado.split() if not palavra.startswith(\"https\"))\n",
    "    \n",
    "    pontuacao = \"[;;?.!-]\"\n",
    "    padronizado = re.compile(pontuacao)\n",
    "    \n",
    "    texto_padronizado = re.sub(padronizado, \" \", texto)\n",
    "    texto_padronizado = texto_padronizado.lower()\n",
    "    texto_saida = \" \"\n",
    "    \n",
    "    for palavra in texto_padronizado.split():\n",
    "        if verifica_k(palavra):\n",
    "            texto_saida = texto_saida + \"hahaha\" #substituindo \"kkk\" por \"hahaha\"\n",
    "        else:\n",
    "            texto_saida = texto_saida + \" \" + palavra\n",
    "    \n",
    "    return texto_saida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando as fun√ß√µes acima nos data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frase in dados_treinamento_relevantes.Treinamento:\n",
    "    treinamento_string_relevantes = treinamento_string_relevantes + frase\n",
    "for frase in dados_treinamento_nao_relevantes.Treinamento:\n",
    "    treinamento_string_nao_relevantes = treinamento_string_nao_relevantes + frase\n",
    "    \n",
    "limpa_texto(treinamento_string_relevantes)\n",
    "limpa_texto(treinamento_string_nao_relevantes)\n",
    "\n",
    "treinamento_pandas_relevantes = pd.Series(treinamento_string_relevantes.split()).value_counts(True)\n",
    "treinamento_pandas_nao_relevantes = pd.Series(treinamento_string_nao_relevantes.split()).value_counts(True)\n",
    "\n",
    "treinamento_pandas_relevantes_total = pd.Series(treinamento_string_relevantes.split()).value_counts()\n",
    "treinamento_pandas_nao_relevantes_total = pd.Series(treinamento_string_nao_relevantes.split()).value_counts()\n",
    "\n",
    "tamanho_tweets_relevantes = len(treinamento_pandas_relevantes_total)\n",
    "tamanho_tweets_nao_relevantes = len(treinamento_pandas_nao_relevantes_total)\n",
    "\n",
    "tamanho_tweets_total = tamanho_tweets_nao_relevantes + tamanho_tweets_relevantes\n",
    "\n",
    "treinamento_pandas_join = pd.Series((treinamento_string_relevantes + treinamento_string_nao_relevantes).split()).value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_nao_relevantes = tamanho_tweets_nao_relevantes / tamanho_tweets_total\n",
    "prob_relevantes = tamanho_tweets_relevantes / tamanho_tweets_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Montando o Classificador ##\n",
    "\n",
    "def classificador_tweets (tweets = \"\", alpha = 1, V = 1250):\n",
    "    \n",
    "    ## limpando os tweets\n",
    "    \n",
    "    texto = limpa_texto(tweets)\n",
    "    \n",
    "    ## avaliando a probabilidade, onde foi feito o uso de log para facilitar a vizualiza√ß√£o dos dados.\n",
    "    \n",
    "    contador_relevantes = 0\n",
    "    contador_nao_relevantes = 0\n",
    "    t_relevantes = tamanho_tweets_relevantes + alpha * V\n",
    "    t_nao_relevantes = tamanho_tweets_nao_relevantes + alpha * V\n",
    "    \n",
    "    for palavra in texto.split():\n",
    "        \n",
    "        if palavra in treinamento_pandas_relevantes:\n",
    "            contador_relevantes += np.log((treinamento_pandas_relevantes_total[palavra] + alpha) / t_relevantes)\n",
    "        else:\n",
    "            contador_relevantes += np.log(alpha / t_relevantes)\n",
    "        if palavra in treinamento_pandas_nao_relevantes:\n",
    "            contador_nao_relevantes += np.log((treinamento_pandas_nao_relevantes_total[palavra] + alpha) / t_nao_relevantes)\n",
    "        else:\n",
    "            contador_nao_relevantes += np.log(alpha / t_nao_relevantes)\n",
    "            \n",
    "    return contador_relevantes > contador_nao_relevantes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora vamos usar a fun√ß√£o classificador_tweets para verificar a performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podemmos perceber, que, da nossa valida√ß√£o 40.0% s√£o relevantes e 60.0% n√£o, de acordo com nossa avalia√ß√£o manual.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Verdadeiro-Verdadeiro': 0.12777777777777777,\n",
       " 'Verdadeiro-Falso': 0.2722222222222222,\n",
       " 'Falso-Verdadeiro': 0.11666666666666667,\n",
       " 'Falso-Falso': 0.48333333333333334,\n",
       " 'Acuracia-Final': '61.111%'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificacao = [int(classificador_tweets(str(tweets), 1, 1250)) for tweets in dados_teste.Teste]\n",
    "\n",
    "dados_teste[\"bayes\"] = classificacao\n",
    "\n",
    "acuracia = {\"Verdadeiro-Verdadeiro\":0,\n",
    "           \"Verdadeiro-Falso\":0,\n",
    "           \"Falso-Verdadeiro\":0,\n",
    "           \"Falso-Falso\":0}\n",
    "\n",
    "for tweets, classificacao_2 in zip(dados_teste.Classifica√ß√£o, dados_teste.bayes):\n",
    "    if tweets and classificacao_2:\n",
    "        acuracia['Verdadeiro-Verdadeiro'] += 1\n",
    "    elif tweets and not classificacao_2:\n",
    "        acuracia['Verdadeiro-Falso'] += 1\n",
    "    elif not tweets and classificacao_2:\n",
    "        acuracia['Falso-Verdadeiro'] += 1\n",
    "    elif not tweets and not classificacao_2:\n",
    "        acuracia['Falso-Falso'] += 1\n",
    "        \n",
    "acuracia_normalizada = {}\n",
    "soma = sum(acuracia.values())\n",
    "for k,v in acuracia.items():\n",
    "    acuracia_normalizada[k] = v/soma\n",
    "acuracia_normalizada['Acuracia-Final'] = str(round((acuracia_normalizada['Verdadeiro-Verdadeiro']+acuracia_normalizada['Falso-Falso'])*100, 3)) + '%'\n",
    "lista.append(acuracia_normalizada['Acuracia-Final'])\n",
    "A = dados_teste.Classifica√ß√£o.value_counts(True)\n",
    "print(\"Podemmos perceber, que, da nossa valida√ß√£o {1}% s√£o relevantes e {0}% n√£o, de acordo com nossa avalia√ß√£o manual.\".format(round(A[0]*100,2),round(A[1]*100, 2)))\n",
    "acuracia_normalizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando o SKLearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A acur√°cia ideal seria: 64.444%'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = dados_treinamento\n",
    "S_teste = dados_teste\n",
    "\n",
    "Xt_train = S['Treinamento']\n",
    "y_train = S['Classifica√ß√£o'] == 1\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "count = CountVectorizer()\n",
    "X_train = count.fit_transform(Xt_train)\n",
    "\n",
    "model = MultinomialNB(alpha=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "Xt_test = [str(h) for h in S_teste[\"Teste\"]]\n",
    "\n",
    "y_test = S_teste['Classifica√ß√£o'] == 1\n",
    "\n",
    "X_test = count.transform(Xt_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\"A acur√°cia ideal seria: {0}%\".format(round(accuracy_score(y_test, y_pred)*100,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ap√≥s a analise de dados, podemos concluir que nosso classificador Naive-Bayes √© horr√≠vel, pois se presumirmos que tudo √© irrelevante ele s√≥ ganha por 1,1%. Isso pode ser explicado por; A baixa quantidade de tweets de treinamento, uma grande dificuldade em classificar se um tweet √© positivo ou negativo, algo muito ambiguo no assunto, ou tamb√©m, porque um mesmo verbo pode ser tanto negativo quanto positivo dificultando ainda mais nosso classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se treinassemos o modelo com os dados que o pr√≥prio modelo produz n√£o teria sentido, pois fazendo isso ele bsicamente s√≥ decoraria os resultados obtidos anteriormente. Treinar nosso modelo com outro modelo at√© seria poss√≠vel, mas seria algo muito mais complexo que envolveria outras t√©cnicas que n√£o aprendemos, como apreendizado cooperativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros usos para o classificador de Naive_Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador de Naive_Bayes tem diversos usos. Alguns exemplos s√£o; classifica√ß√£o de spam de emails, diagnostico de alguma doen√ßa, previs√£o do tempo e diversos outros usos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "[Naive_Bayes Classification](https://www.datageeks.com.br/naive-bayes/) **Outra fonte utilizada**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
